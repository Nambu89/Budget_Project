"""
Tests de conexiÃ³n con Azure AI Foundry / OpenAI.

Verifica que la conexiÃ³n con el LLM estÃ© funcionando
correctamente y que las respuestas sean vÃ¡lidas.
"""

import pytest
import os
import sys
from pathlib import Path

# AÃ±adir el directorio raÃ­z al path
ROOT_DIR = Path(__file__).parent.parent.parent
sys.path.insert(0, str(ROOT_DIR))

from src.config.settings import settings
from src.infrastructure.llm import (
    AzureOpenAIClient,
    OpenAIClient,
    LLMFactory,
    get_llm_client,
)


class TestAzureConnection:
    """Tests de conexiÃ³n con Azure OpenAI."""
    
    @pytest.mark.skipif(
        not os.getenv("AZURE_OPENAI_API_KEY"),
        reason="AZURE_OPENAI_API_KEY no configurada"
    )
    def test_azure_client_initialization(self):
        """Test: El cliente Azure se inicializa correctamente."""
        client = AzureOpenAIClient()
        
        assert client is not None
        assert client.client is not None
        assert client.deployment is not None
        print(f"âœ… Cliente Azure inicializado: deployment={client.deployment}")
    
    @pytest.mark.skipif(
        not os.getenv("AZURE_OPENAI_API_KEY"),
        reason="AZURE_OPENAI_API_KEY no configurada"
    )
    def test_azure_simple_completion(self):
        """Test: Azure responde a un prompt simple."""
        client = AzureOpenAIClient()
        
        response = client.simple_completion(
            prompt="Responde solo con la palabra 'OK'",
            temperature=0,
            max_tokens=10,
        )
        
        assert response is not None
        assert len(response) > 0
        print(f"âœ… Respuesta Azure: {response}")
    
    @pytest.mark.skipif(
        not os.getenv("AZURE_OPENAI_API_KEY"),
        reason="AZURE_OPENAI_API_KEY no configurada"
    )
    def test_azure_chat_completion(self):
        """Test: Azure responde a una conversaciÃ³n."""
        client = AzureOpenAIClient()
        
        messages = [
            {"role": "system", "content": "Eres un asistente Ãºtil."},
            {"role": "user", "content": "Â¿CuÃ¡nto es 2+2? Responde solo el nÃºmero."},
        ]
        
        response = client.chat_completion(
            messages=messages,
            temperature=0,
            max_tokens=10,
        )
        
        assert response is not None
        assert "4" in response
        print(f"âœ… Chat completion Azure: {response}")
    
    @pytest.mark.skipif(
        not os.getenv("AZURE_OPENAI_API_KEY"),
        reason="AZURE_OPENAI_API_KEY no configurada"
    )
    def test_azure_is_available(self):
        """Test: Verificar disponibilidad del servicio Azure."""
        client = AzureOpenAIClient()
        
        available = client.is_available()
        
        assert available is True
        print("âœ… Servicio Azure disponible")


class TestOpenAIConnection:
    """Tests de conexiÃ³n con OpenAI directo."""
    
    @pytest.mark.skipif(
        not os.getenv("OPENAI_API_KEY"),
        reason="OPENAI_API_KEY no configurada"
    )
    def test_openai_client_initialization(self):
        """Test: El cliente OpenAI se inicializa correctamente."""
        client = OpenAIClient()
        
        assert client is not None
        assert client.client is not None
        assert client.model is not None
        print(f"âœ… Cliente OpenAI inicializado: model={client.model}")
    
    @pytest.mark.skipif(
        not os.getenv("OPENAI_API_KEY"),
        reason="OPENAI_API_KEY no configurada"
    )
    def test_openai_simple_completion(self):
        """Test: OpenAI responde a un prompt simple."""
        client = OpenAIClient()
        
        response = client.simple_completion(
            prompt="Responde solo con la palabra 'OK'",
            temperature=0,
            max_tokens=10,
        )
        
        assert response is not None
        assert len(response) > 0
        print(f"âœ… Respuesta OpenAI: {response}")


class TestLLMFactory:
    """Tests del factory de LLM."""
    
    def test_factory_get_provider_info(self):
        """Test: Factory retorna informaciÃ³n del proveedor."""
        info = LLMFactory.get_provider_info()
        
        assert "provider" in info
        assert "azure_configured" in info
        # Verificar que al menos uno estÃ¡ en el dict (compatibilidad)
        assert "azure_configured" in info or "openai_configured" in info
        print(f"âœ… Provider info: {info}")
    
    @pytest.mark.skipif(
        not (os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")),
        reason="NingÃºn LLM configurado"
    )
    def test_factory_creates_client(self):
        """Test: Factory crea el cliente correcto."""
        # Reset singleton
        LLMFactory.reset()
        
        client = LLMFactory.create()
        
        assert client is not None
        print(f"âœ… Factory creÃ³ cliente: {type(client).__name__}")
    
    @pytest.mark.skipif(
        not (os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")),
        reason="NingÃºn LLM configurado"
    )
    def test_factory_singleton(self):
        """Test: Factory retorna la misma instancia (singleton)."""
        LLMFactory.reset()
        
        client1 = LLMFactory.create()
        client2 = LLMFactory.create()
        
        assert client1 is client2
        print("âœ… Factory singleton funciona correctamente")
    
    @pytest.mark.skipif(
        not (os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")),
        reason="NingÃºn LLM configurado"
    )
    def test_get_llm_client_convenience(self):
        """Test: FunciÃ³n de conveniencia get_llm_client."""
        LLMFactory.reset()
        
        client = get_llm_client()
        
        assert client is not None
        print(f"âœ… get_llm_client retorna: {type(client).__name__}")


class TestConnectionIntegration:
    """Tests de integraciÃ³n de conexiÃ³n."""
    
    @pytest.mark.skipif(
        not (os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")),
        reason="NingÃºn LLM configurado"
    )
    def test_llm_responds_about_construction(self):
        """Test: LLM responde preguntas sobre construcciÃ³n."""
        client = get_llm_client()
        
        response = client.simple_completion(
            prompt="Â¿CuÃ¡l es el precio aproximado por m2 de alicatar un baÃ±o en EspaÃ±a? Responde brevemente.",
            system_prompt="Eres un experto en reformas en EspaÃ±a.",
            temperature=0.3,
            max_tokens=100,
        )
        
        assert response is not None
        assert len(response) > 20
        # DeberÃ­a mencionar euros o â‚¬
        assert "â‚¬" in response or "euro" in response.lower() or "eur" in response.lower()
        print(f"âœ… LLM responde sobre construcciÃ³n:\n{response[:200]}...")
    
    @pytest.mark.skipif(
        not (os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")),
        reason="NingÃºn LLM configurado"
    )
    def test_llm_structured_response(self):
        """Test: LLM puede generar respuestas estructuradas."""
        client = get_llm_client()
        
        response = client.simple_completion(
            prompt="""
            Genera un JSON con la siguiente estructura para un presupuesto de baÃ±o:
            {"partidas": [{"nombre": "...", "precio": 0}], "total": 0}
            
            Incluye 3 partidas bÃ¡sicas. Solo responde con el JSON, nada mÃ¡s.
            """,
            temperature=0,
            max_tokens=200,
        )
        
        assert response is not None
        assert "{" in response and "}" in response
        print(f"âœ… LLM genera respuesta estructurada:\n{response}")


# ============================================
# Ejecutar tests directamente
# ============================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª Tests de ConexiÃ³n LLM")
    print("=" * 60)
    
    # Verificar configuraciÃ³n
    print(f"\nğŸ“‹ ConfiguraciÃ³n detectada:")
    print(f"   LLM Provider: {settings.llm_provider}")
    print(f"   Azure configurado: {settings.is_azure_configured()}")
    print(f"   OpenAI configurado: {settings.is_openai_configured()}")
    
    # Ejecutar pytest
    pytest.main([__file__, "-v", "-s"])